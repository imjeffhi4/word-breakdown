
import re
import enum
from transformers import TextGenerationPipeline

class ReturnType(enum.Enum):
    TENSORS = 0
    NEW_TEXT = 1
    FULL_TEXT = 2
    
class WordBreakdownPipeline(TextGenerationPipeline):
    def preprocess(self, prompt_dict, prefix="", handle_long_generation=None, **generate_kwargs):
        word = prompt_dict['word']
        split_word = ' '.join(word)
        try:
            definition = prompt_dict['definition']
        except:
            definition = None
        if definition:
            prompt_text = f'<s> {word} {split_word} <DEF> {definition} <SYLLABLES>'
        else:
            prompt_text =  f'<s> {word} {split_word} <DEF>'
        inputs = self.tokenizer(
            prefix + prompt_text, padding=False, add_special_tokens=False, return_tensors=self.framework
        )
        inputs["prompt_text"] = prompt_text

        if handle_long_generation == "hole":
            cur_len = inputs["input_ids"].shape[-1]
            if "max_new_tokens" in generate_kwargs:
                new_tokens = generate_kwargs["max_new_tokens"]
            else:
                new_tokens = generate_kwargs.get("max_length", self.model.config.max_length) - cur_len
                if new_tokens < 0:
                    raise ValueError("We cannot infer how many new tokens are expected")
            if cur_len + new_tokens > self.tokenizer.model_max_length:
                keep_length = self.tokenizer.model_max_length - new_tokens
                if keep_length <= 0:
                    raise ValueError(
                        "We cannot use `hole` to handle this generation the number of desired tokens exceeds the"
                        " models max length"
                    )

                inputs["input_ids"] = inputs["input_ids"][:, -keep_length:]
                if "attention_mask" in inputs:
                    inputs["attention_mask"] = inputs["attention_mask"][:, -keep_length:]

        return inputs

    def get_etymology(self, ety_txt: str):
        """Parses text to return a list of dict containing the etymology compound and definitions"""
        etys = re.findall('<ETY>.+?(?=<ETY>|$)', ety_txt)
        for ety in etys:
            compound = re.findall("<ETY>(.+?)(?=<DEF>|$)", ety)[0].strip()
            if "<NULL>" not in compound:
                ety_dict = {
                    "Etymology Compound": re.findall("<ETY>(.+?)(?=<DEF>)", ety)[0].strip(),
                    "Compound Meaning": re.findall("<DEF>(.+)", ety)[0].strip()
                }
                yield ety_dict
            else:
                yield {"Etymology Compound": None, "Compound Meaning": None}


    def parse_morphemes(self, morph_txt: str):
        """Parses text to return a list of affixes and a definition for each affix"""
        morphs = re.findall('<MORPH>.+?(?=<MORPH>|$)', morph_txt)
        for morph in morphs:
            yield {
                "Morpheme": re.findall("<MORPH>(.+?)(?=<DEF>)", morph)[0].strip(),
                "Definition": re.findall("<DEF>(.+?)(?=<ETY>)", morph)[0].strip(),
                "Etymology Compounds": list(self.get_etymology(re.findall("(<ETY>.+?)$", morph)[0].strip()))
            }

    def postprocess(self, model_outputs, return_type=ReturnType.FULL_TEXT):
        """Takes in the output generated by the model. Returns a dictionary of the word breakdown."""
        generated_sequence = model_outputs["generated_sequence"][0]
        input_ids = model_outputs["input_ids"]
        prompt_text = model_outputs["prompt_text"]
        generated_sequence = generated_sequence.numpy().tolist()
        records = []
        for sequence in generated_sequence:
            if return_type == ReturnType.TENSORS:
                record = {"generated_token_ids": sequence}
            elif return_type in {ReturnType.NEW_TEXT, ReturnType.FULL_TEXT}:
                # Decode text
                text = self.tokenizer.decode(
                    sequence,
                    skip_special_tokens=False,
                )

                # Remove PADDING prompt of the sequence if XLNet or Transfo-XL model is used
                if input_ids is None:
                    prompt_length = 0
                else:
                    prompt_length = len(
                        self.tokenizer.decode(
                            input_ids[0],
                            skip_special_tokens=False,
                        )
                    )

                if return_type == ReturnType.FULL_TEXT:
                    all_text = prompt_text + text[prompt_length:]
                else:
                    all_text = text[prompt_length:]
                postprocessed_dict =  {
                    "Word": re.findall('<s> (.+?)(?= \w )', all_text)[0].strip().replace(' ', ''),
                    "Definition": re.findall("<DEF>(.+?)(?=<SYLLABLES>)", all_text)[0].strip(),
                    "Syllables": re.findall("<SYLLABLES> (.+?)(?=<MORPH>)", all_text)[0].strip().split(' '),
                    "Morphemes": list(self.parse_morphemes(re.findall("(<MORPH>.+?)(?=</s>)", all_text)[0].strip()))
                }
                record = {"generated_breakdown": postprocessed_dict}
            records.append(record)
        return records
